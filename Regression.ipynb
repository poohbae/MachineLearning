{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Section 2.1 – DATASET DESCRIPTION AND ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Load the Ames Housing dataset\n",
    "df = pd.read_csv(\"AmesHousing.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of data types and missing values\n",
    "print(\"\\n--- Data Info ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_cols)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"SalePrice\"\n",
    "print(\"\\nTarget Summary:\")\n",
    "print(df[target].describe())\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(df[target], kde=True, color='skyblue')\n",
    "plt.title(\"Distribution of Sale Price\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness:\", df[target].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a91a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(numeric_only=True)[target].sort_values(ascending=False)\n",
    "print(\"\\nTop 10 Correlated Features with SalePrice:\")\n",
    "print(corr.head(10))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "corr.head(10).drop(target).plot(kind='barh', color='lightgreen')\n",
    "plt.title(\"Top Correlated Features with SalePrice\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Overall Qual', y='SalePrice', data=df, hue='Overall Qual', palette='Blues', legend=False)\n",
    "plt.title(\"Sale Price vs Overall Quality\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x='Neighborhood', y='SalePrice', data=df)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Sale Price by Neighborhood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEDA Summary:\")\n",
    "print(f\"- Total records: {df.shape[0]} | Total features: {df.shape[1]}\")\n",
    "print(f\"- {len(categorical_cols)} categorical, {len(numeric_cols)} numeric features.\")\n",
    "print(f\"- {missing.count()} features contain missing values.\")\n",
    "print(f\"- SalePrice is right-skewed ({round(df[target].skew(),2)}).\")\n",
    "print(\"- Strongly correlated features include OverallQual, GrLivArea, and GarageCars.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 2.2 – DATA PRE-PROCESSING AND CLEANING\n",
    "# ============================================\n",
    "\n",
    "# Check total missing values again\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "missing.head(10)\n",
    "\n",
    "# Fill numeric columns with median, categorical with mode\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        mode_value = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_value)\n",
    "    else:\n",
    "        median_value = df[col].median()\n",
    "        df[col] = df[col].fillna(median_value)\n",
    "\n",
    "# Confirm no missing values remain\n",
    "print(\"Remaining missing values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf835217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR for key numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in [\"Lot Area\", \"Gr Liv Area\", \"SalePrice\"]:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df[col] = np.where(df[col] > upper, upper,\n",
    "                np.where(df[col] < lower, lower, df[col]))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x=df[\"SalePrice\"], color='lightblue')\n",
    "plt.title(\"Boxplot after Outlier Capping (SalePrice)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a36e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Apply one-hot encoding for categorical features\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"New dataset shape after encoding:\", df_encoded.shape)\n",
    "df_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target\n",
    "X = df_encoded.drop(\"SalePrice\", axis=1)\n",
    "y = df_encoded[\"SalePrice\"]\n",
    "\n",
    "# Apply standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Check first few scaled values\n",
    "X_scaled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76eb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine scaled features and target for later use\n",
    "cleaned_df = pd.concat([X_scaled, y], axis=1)\n",
    "\n",
    "# Save to new CSV\n",
    "cleaned_df.to_csv(\"AmesHousing_Cleaned.csv\", index=False)\n",
    "print(\"Cleaned dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 2.3 – FEATURE ENGINEERING\n",
    "# ============================================\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load the cleaned dataset produced in Section 2.2\n",
    "df_encoded = pd.read_csv(\"AmesHousing_Cleaned.csv\")\n",
    "\n",
    "print(\"Loaded cleaned dataset:\", df_encoded.shape)\n",
    "df_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new numerical features from existing columns\n",
    "df_encoded[\"TotalSF\"] = df_encoded[\"Total Bsmt SF\"] + df_encoded[\"Gr Liv Area\"]\n",
    "df_encoded[\"TotalBath\"] = (\n",
    "    df_encoded.get(\"Full Bath\", 0)\n",
    "    + 0.5 * df_encoded.get(\"Half Bath\", 0)\n",
    "    + df_encoded.get(\"Bsmt Full Bath\", 0)\n",
    "    + 0.5 * df_encoded.get(\"Bsmt Half Bath\", 0)\n",
    ")\n",
    "df_encoded[\"AgeOfHouse\"] = 2025 - df_encoded[\"Year Built\"]\n",
    "\n",
    "# Verify creation\n",
    "df_encoded[[\"TotalSF\", \"TotalBath\", \"AgeOfHouse\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6753eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df_encoded.drop(\"SalePrice\", axis=1)\n",
    "y = df_encoded[\"SalePrice\"]\n",
    "\n",
    "# Train LightGBM\n",
    "lgb = LGBMRegressor(random_state=42)\n",
    "lgb.fit(X, y)\n",
    "\n",
    "# Feature importance plot\n",
    "importance = pd.Series(lgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "importance.head(15).plot(kind='barh', figsize=(7,5), color='lightgreen')\n",
    "plt.title(\"Top 15 Important Features (LightGBM)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 20 most important predictors\n",
    "selected_features = importance.head(20).index.tolist()\n",
    "X_selected = df_encoded[selected_features]\n",
    "y = df_encoded[\"SalePrice\"]\n",
    "\n",
    "# Print selected features 5 per row\n",
    "print(\"Selected features for modelling:\")\n",
    "for i in range(0, len(selected_features), 5):\n",
    "    row = selected_features[i:i+5]\n",
    "    print(\", \".join(row))\n",
    "\n",
    "print(\"\\nX_selected shape:\", X_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768cc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 2.4 – MODEL IMPLEMENTATION\n",
    "# ============================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define target and features\n",
    "target = \"SalePrice\"\n",
    "X = df_encoded.drop(target, axis=1)\n",
    "y = df_encoded[target]\n",
    "\n",
    "# Split data (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"| Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc31ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elastic Net model\n",
    "en_model = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "en_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_en = en_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mae_en = mean_absolute_error(y_test, y_pred_en)\n",
    "rmse_en = np.sqrt(mean_squared_error(y_test, y_pred_en))\n",
    "r2_en = r2_score(y_test, y_pred_en)\n",
    "\n",
    "print(f\"Elastic Net → MAE: {mae_en:.2f}, RMSE: {rmse_en:.2f}, R²: {r2_en:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LightGBM model\n",
    "lgb_model = LGBMRegressor(random_state=42, n_estimators=300, learning_rate=0.05)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"LightGBM → MAE: {mae_lgb:.2f}, RMSE: {rmse_lgb:.2f}, R²: {r2_lgb:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred_en, alpha=0.6, label=\"Elastic Net\")\n",
    "plt.scatter(y_test, y_pred_lgb, alpha=0.6, label=\"LightGBM\")\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Sale Price\")\n",
    "plt.ylabel(\"Predicted Sale Price\")\n",
    "plt.title(\"Actual vs Predicted Sale Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911cf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 2.5 – MODEL TUNING AND OPTIMIZATION\n",
    "# ============================================\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Elastic Net\n",
    "param_grid_en = {\n",
    "    'alpha': [0.01, 0.1, 1, 10],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "en = ElasticNet(random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation grid search\n",
    "grid_en = GridSearchCV(\n",
    "    estimator=en,\n",
    "    param_grid=param_grid_en,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_en.fit(X_train, y_train)\n",
    "\n",
    "# Display best parameters and score\n",
    "print(\"Best ElasticNet parameters:\", grid_en.best_params_)\n",
    "print(\"Best cross-validated R²:\", grid_en.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_en = grid_en.best_estimator_\n",
    "y_pred_en_tuned = best_en.predict(X_test)\n",
    "\n",
    "mae_en_tuned = mean_absolute_error(y_test, y_pred_en_tuned)\n",
    "rmse_en_tuned = np.sqrt(mean_squared_error(y_test, y_pred_en_tuned))\n",
    "r2_en_tuned = r2_score(y_test, y_pred_en_tuned)\n",
    "\n",
    "print(f\"Tuned Elastic Net → MAE: {mae_en_tuned:.2f}, RMSE: {rmse_en_tuned:.2f}, R²: {r2_en_tuned:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914181ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for LightGBM\n",
    "param_grid_lgb = {\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [6, 8, 10]\n",
    "}\n",
    "\n",
    "lgb = LGBMRegressor(random_state=42)\n",
    "\n",
    "grid_lgb = GridSearchCV(\n",
    "    estimator=lgb,\n",
    "    param_grid=param_grid_lgb,\n",
    "    scoring='r2',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_lgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LightGBM parameters:\", grid_lgb.best_params_)\n",
    "print(\"Best cross-validated R²:\", grid_lgb.best_score_)\n",
    "\n",
    "# Evaluate best model\n",
    "best_lgb = grid_lgb.best_estimator_\n",
    "y_pred_lgb_tuned = best_lgb.predict(X_test)\n",
    "\n",
    "mae_lgb_tuned = mean_absolute_error(y_test, y_pred_lgb_tuned)\n",
    "rmse_lgb_tuned = np.sqrt(mean_squared_error(y_test, y_pred_lgb_tuned))\n",
    "r2_lgb_tuned = r2_score(y_test, y_pred_lgb_tuned)\n",
    "\n",
    "print(f\"Tuned LightGBM → MAE: {mae_lgb_tuned:.2f}, RMSE: {rmse_lgb_tuned:.2f}, R²: {r2_lgb_tuned:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aeafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['ElasticNet (Tuned)', 'LightGBM (Tuned)'],\n",
    "    'MAE': [mae_en_tuned, mae_lgb_tuned],\n",
    "    'RMSE': [rmse_en_tuned, rmse_lgb_tuned],\n",
    "    'R²': [r2_en_tuned, r2_lgb_tuned]\n",
    "})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals for both models\n",
    "residuals_en = y_test - y_pred_en_tuned\n",
    "residuals_lgb = y_test - y_pred_lgb_tuned\n",
    "\n",
    "# Plot residual distributions\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.kdeplot(residuals_en, label='Elastic Net', fill=True)\n",
    "sns.kdeplot(residuals_lgb, label='LightGBM', fill=True)\n",
    "plt.title(\"Residual Error Distribution\")\n",
    "plt.xlabel(\"Prediction Error (Actual - Predicted)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8643cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_en = cross_val_score(best_en, X, y, scoring='r2', cv=5)\n",
    "cv_lgb = cross_val_score(best_lgb, X, y, scoring='r2', cv=5)\n",
    "\n",
    "print(\"Elastic Net CV R² scores:\", cv_en)\n",
    "print(\"LightGBM CV R² scores:\", cv_lgb)\n",
    "\n",
    "print(\"\\nMean CV R²:\")\n",
    "print(\"Elastic Net:\", cv_en.mean())\n",
    "print(\"LightGBM:\", cv_lgb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 2.7 – MODEL EXPLAINABILITY\n",
    "# ============================================\n",
    "\n",
    "import shap\n",
    "\n",
    "# Create SHAP explainer for the tuned LightGBM model\n",
    "explainer = shap.TreeExplainer(best_lgb)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Generate SHAP summary bar plot for top features\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\", max_display=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how TotalSF affects the predicted SalePrice\n",
    "shap.dependence_plot(\"TotalSF\", shap_values, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
