{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 3.1 – DATASET DESCRIPTION AND ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"AdultIncome.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Data Info ---\")\n",
    "df.info()\n",
    "\n",
    "# Replace '?' with NaN in the entire DataFrame\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column names\n",
    "df.columns = [col.strip().replace(\".\", \"_\") for col in df.columns]\n",
    "\n",
    "# Print 5 columns per row\n",
    "cols = df.columns.tolist()\n",
    "for i in range(0, len(cols), 5):\n",
    "    print(cols[i:i+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x='income', hue='income', data=df, palette='cool', legend=False)\n",
    "plt.title(\"Class Distribution: <=50K vs >50K\")\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(df['income'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numeric features:\", numeric_cols)\n",
    "\n",
    "df[numeric_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x='income', y='age', hue='income', data=df, palette='pastel', legend=False)\n",
    "plt.title(\"Age Distribution by Income Group\")\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x='income', y='hours_per_week', hue='income', data=df, palette='pastel', legend=False)\n",
    "plt.title(\"Weekly Working Hours by Income Group\")\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Hours per Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 3.2 – DATA PRE-PROCESSING AND HANDLING IMBALANCE\n",
    "# ============================================\n",
    "# Count missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "print(\"\\nAfter cleaning, dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0575ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "\n",
    "# Apply label encoding\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "print(\"\\nAfter encoding:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Target class distribution (train):\", y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply Synthetic Minority Oversampling Technique (SMOTE)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before resampling:\", y_train.value_counts())\n",
    "print(\"After resampling:\", y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train_resampled.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Apply scaling only to numeric columns\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train_resampled[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(\"Numeric features scaled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be3ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 3.3 - FEATURE ENGINEERING\n",
    "# ============================================\n",
    "\n",
    "# Compute correlation with target (income)\n",
    "corr = df.corr()['income'].sort_values(ascending=False)\n",
    "print(\"Top correlated features with income:\")\n",
    "print(corr.head(10))\n",
    "\n",
    "# Visualize correlations with income\n",
    "plt.figure(figsize=(7,5))\n",
    "corr.head(10).drop('income').plot(kind='barh', color='lightblue')\n",
    "plt.title(\"Top Features Correlated with Income\")\n",
    "plt.xlabel(\"Correlation Coefficient\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08356497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total capital feature\n",
    "df['total_capital'] = df['capital_gain'] - df['capital_loss']\n",
    "\n",
    "# Create working_hours_group\n",
    "df['working_hours_group'] = pd.cut(\n",
    "    df['hours_per_week'],\n",
    "    bins=[0, 35, 45, 60, 100],\n",
    "    labels=['Part-time', 'Full-time', 'Overtime', 'Extreme']\n",
    ")\n",
    "\n",
    "# Encode new categorical feature\n",
    "le = LabelEncoder()\n",
    "df['working_hours_group'] = le.fit_transform(df['working_hours_group'].astype(str))\n",
    "print(df[['hours_per_week', 'working_hours_group', 'total_capital']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a980866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Prepare dataset for feature importance evaluation\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n",
    "\n",
    "model = LGBMClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.barplot(x=importances.head(15), y=importances.head(15).index, color='lightgreen')\n",
    "plt.title(\"Top 15 Important Features (LightGBM)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dac23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features for model training\n",
    "selected_features = [\n",
    "    'education_num', 'capital_gain', 'hours_per_week',\n",
    "    'age', 'marital_status', 'occupation', 'total_capital'\n",
    "]\n",
    "\n",
    "X_selected = df[selected_features]\n",
    "y = df['income']\n",
    "\n",
    "print(\"Selected feature set:\", X_selected.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ded67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 3.4 – MODEL IMPLEMENTATION\n",
    "# ============================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Split dataset again using selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline Logistic Regression model\n",
    "log_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "y_proba_log = log_model.predict_proba(X_test)[:, 1]  # probability for ROC-AUC\n",
    "\n",
    "# Evaluate metrics\n",
    "acc_log  = accuracy_score(y_test, y_pred_log)\n",
    "prec_log = precision_score(y_test, y_pred_log)\n",
    "rec_log  = recall_score(y_test, y_pred_log)\n",
    "f1_log   = f1_score(y_test, y_pred_log)\n",
    "auc_log  = roc_auc_score(y_test, y_proba_log)\n",
    "\n",
    "print(f\"Logistic Regression → Accuracy: {acc_log:.3f}, Precision: {prec_log:.3f}, Recall: {rec_log:.3f}, \"\n",
    "      f\"F1: {f1_log:.3f}, ROC-AUC: {auc_log:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55375f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train tuned LightGBM Classifier\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "y_proba_lgb = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate metrics\n",
    "acc_lgb  = accuracy_score(y_test, y_pred_lgb)\n",
    "prec_lgb = precision_score(y_test, y_pred_lgb)\n",
    "rec_lgb  = recall_score(y_test, y_pred_lgb)\n",
    "f1_lgb   = f1_score(y_test, y_pred_lgb)\n",
    "auc_lgb  = roc_auc_score(y_test, y_proba_lgb)\n",
    "\n",
    "print(f\"LightGBM → Accuracy: {acc_lgb:.3f}, Precision: {prec_lgb:.3f}, Recall: {rec_lgb:.3f}, \"\n",
    "      f\"F1: {f1_lgb:.3f}, ROC-AUC: {auc_lgb:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d640037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results into summary table\n",
    "results_cls = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'LightGBM Classifier'],\n",
    "    'Accuracy': [acc_log, acc_lgb],\n",
    "    'Precision': [prec_log, prec_lgb],\n",
    "    'Recall': [rec_log, rec_lgb],\n",
    "    'F1-Score': [f1_log, f1_lgb],\n",
    "    'ROC-AUC': [auc_log, auc_lgb]\n",
    "})\n",
    "print(results_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80063420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 3.5 – MODEL TUNING AND OPTIMIZATION\n",
    "# ============================================\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid for Logistic Regression\n",
    "param_grid_log = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid_log = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    param_grid=param_grid_log,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_log.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression parameters:\", grid_log.best_params_)\n",
    "print(\"Best cross-validated ROC-AUC:\", grid_log.best_score_)\n",
    "\n",
    "# Evaluate tuned model\n",
    "best_log = grid_log.best_estimator_\n",
    "y_pred_log_tuned = best_log.predict(X_test)\n",
    "y_proba_log_tuned = best_log.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_log_tuned  = accuracy_score(y_test, y_pred_log_tuned)\n",
    "prec_log_tuned = precision_score(y_test, y_pred_log_tuned)\n",
    "rec_log_tuned  = recall_score(y_test, y_pred_log_tuned)\n",
    "f1_log_tuned   = f1_score(y_test, y_pred_log_tuned)\n",
    "auc_log_tuned  = roc_auc_score(y_test, y_proba_log_tuned)\n",
    "\n",
    "print(f\"Tuned Logistic Regression → Accuracy: {acc_log_tuned:.3f}, Precision: {prec_log_tuned:.3f}, \"\n",
    "      f\"Recall: {rec_log_tuned:.3f}, F1: {f1_log_tuned:.3f}, ROC-AUC: {auc_log_tuned:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1accdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for LightGBM\n",
    "param_grid_lgb = {\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [6, 8, 10]\n",
    "}\n",
    "\n",
    "grid_lgb = GridSearchCV(\n",
    "    estimator=LGBMClassifier(random_state=42),\n",
    "    param_grid=param_grid_lgb,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_lgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LightGBM parameters:\", grid_lgb.best_params_)\n",
    "print(\"Best cross-validated ROC-AUC:\", grid_lgb.best_score_)\n",
    "\n",
    "# Evaluate tuned model\n",
    "best_lgb_cls = grid_lgb.best_estimator_\n",
    "y_pred_lgb_tuned = best_lgb_cls.predict(X_test)\n",
    "y_proba_lgb_tuned = best_lgb_cls.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_lgb_tuned  = accuracy_score(y_test, y_pred_lgb_tuned)\n",
    "prec_lgb_tuned = precision_score(y_test, y_pred_lgb_tuned)\n",
    "rec_lgb_tuned  = recall_score(y_test, y_pred_lgb_tuned)\n",
    "f1_lgb_tuned   = f1_score(y_test, y_pred_lgb_tuned)\n",
    "auc_lgb_tuned  = roc_auc_score(y_test, y_proba_lgb_tuned)\n",
    "\n",
    "print(f\"Tuned LightGBM → Accuracy: {acc_lgb_tuned:.3f}, Precision: {prec_lgb_tuned:.3f}, \"\n",
    "      f\"Recall: {rec_lgb_tuned:.3f}, F1: {f1_lgb_tuned:.3f}, ROC-AUC: {auc_lgb_tuned:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tuned = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression (Tuned)', 'LightGBM (Tuned)'],\n",
    "    'Accuracy': [acc_log_tuned, acc_lgb_tuned],\n",
    "    'Precision': [prec_log_tuned, prec_lgb_tuned],\n",
    "    'Recall': [rec_log_tuned, rec_lgb_tuned],\n",
    "    'F1-Score': [f1_log_tuned, f1_lgb_tuned],\n",
    "    'ROC-AUC': [auc_log_tuned, auc_lgb_tuned]\n",
    "})\n",
    "print(results_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63948fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 3.6 – EVALUATION AND PERFORMANCE METRICS\n",
    "# ============================================\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Logistic Regression\n",
    "cm_log = confusion_matrix(y_test, y_pred_log_tuned)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_log).plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Logistic Regression (Tuned)\")\n",
    "plt.show()\n",
    "\n",
    "# LightGBM\n",
    "cm_lgb = confusion_matrix(y_test, y_pred_lgb_tuned)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_lgb).plot(cmap='Greens')\n",
    "plt.title(\"Confusion Matrix - LightGBM (Tuned)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9da337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, y_proba_log_tuned)\n",
    "fpr_lgb, tpr_lgb, _ = roc_curve(y_test, y_proba_lgb_tuned)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr_log, tpr_log, label=f\"Logistic Regression (AUC = {auc_log_tuned:.3f})\")\n",
    "plt.plot(fpr_lgb, tpr_lgb, label=f\"LightGBM (AUC = {auc_lgb_tuned:.3f})\")\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "prec_log_curve, rec_log_curve, _ = precision_recall_curve(y_test, y_proba_log_tuned)\n",
    "prec_lgb_curve, rec_lgb_curve, _ = precision_recall_curve(y_test, y_proba_lgb_tuned)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(rec_log_curve, prec_log_curve, label=\"Logistic Regression\")\n",
    "plt.plot(rec_lgb_curve, prec_lgb_curve, label=\"LightGBM\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 3.7 – MODEL EXPLAINABILITY\n",
    "# ============================================\n",
    "\n",
    "# Extract feature importance (coefficients)\n",
    "coef = pd.Series(best_log.coef_[0], index=X_selected.columns)\n",
    "coef_sorted = coef.sort_values()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.barplot(x=coef_sorted.values, y=coef_sorted.index, hue=coef_sorted.index, palette=\"coolwarm\", legend=False)\n",
    "plt.title(\"Feature Coefficients - Logistic Regression (Tuned)\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "# Display top coefficients numerically\n",
    "print(coef_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Explain tuned LightGBM classifier\n",
    "explainer = shap.TreeExplainer(best_lgb_cls)\n",
    "shap_values = explainer.shap_values(X_selected)\n",
    "\n",
    "# Global importance\n",
    "shap.summary_plot(shap_values, X_selected, plot_type=\"bar\", max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the effect of education_num on predictions\n",
    "shap.dependence_plot(\"education_num\", shap_values, X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 4.1 - CLASSIFICATION METRIC COMPARISON (BEFORE VS AFTER TUNING)\n",
    "# ============================================\n",
    "\n",
    "metrics_cls = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Logistic Regression (Tuned)', 'LightGBM', 'LightGBM (Tuned)'],\n",
    "    'Accuracy': [acc_log, acc_log_tuned, acc_lgb, acc_lgb_tuned],\n",
    "    'F1-Score': [f1_log, f1_log_tuned, f1_lgb, f1_lgb_tuned],\n",
    "    'ROC-AUC': [auc_log, auc_log_tuned, auc_lgb, auc_lgb_tuned]\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics_cls.plot(x='Model', y='Accuracy', kind='bar', color='lightgreen', ax=axes[0])\n",
    "axes[0].set_title('Accuracy Comparison')\n",
    "axes[0].set_ylim(0.7, 0.9)\n",
    "\n",
    "metrics_cls.plot(x='Model', y='F1-Score', kind='bar', color='skyblue', ax=axes[1])\n",
    "axes[1].set_title('F1-Score Comparison')\n",
    "\n",
    "metrics_cls.plot(x='Model', y='ROC-AUC', kind='bar', color='salmon', ax=axes[2])\n",
    "axes[2].set_title('ROC-AUC Comparison')\n",
    "\n",
    "plt.suptitle('Classification Model Performance Before and After Tuning', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SECTION 4.1 - CLASSIFICATION ACTUAL VS PREDICTED (CONFUSION MATRIX)\n",
    "# ============================================\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_lgb_tuned)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap='Greens')\n",
    "plt.title('LightGBM Classifier – Actual vs Predicted Income Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
